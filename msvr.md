# Introduction

## Science and Data

\notebox{The core of our modern scientific knowledge is based on careful production and analysis of experimental data.}

- Specify an hypothesis
- Collect data through experiments
- Describe the measurements with a mathematical function
- Replicate

## Sumarizing data with model

Using a parametric model, we can describe our data using adjustable parameters; these parameters change the behavior of the function according to some particularities of our data.
For example, the SIR model for spread of diseases:


\begin{empheq}[box=\mybox]{align*}
\frac{dS}{dt} &= - \beta S(t) I(t)
\end{empheq}

where $\beta$ is the average number of contacts per day with infected people or not.

## Sumarizing data with model

When collecting data from different populations, the observed value of $\beta$ will be different, large densities cities will have a larger value.

Not only that, but a more detailed model can incorporates other aspects of the population such as: use of masks, vaccination, genetic factors, etc.

## One model to fit them all

We want a mathematical model that is capable of accuretaly describing the phenomena of interest but being also adaptable for variations in the samples.

\begin{empheq}[box=\mybox]{align*}
    \min_{f}{agg_{i=1 .. k}{\left(\min_{\theta^i}\mathcal{L}(f(x^i; \theta^i), y^i)\right)}},
    \label{eq:mvsrfit}
\end{empheq}

where the superscript $i$ refers to the index of each dataset, $agg$ is an aggregation function such as $max, avg, med$, $x \in \mathbb{R}^m, \theta \in \mathbb{R}^n$, $n \in \mathbb{N}$, $l < n < u$.

## Dealing with multiple views

Overall, given $k$ different datasets, we want to find the function $f$ with a limited number of parameters that minimizes the aggregated value of $\mathcal{L}$ for each dataset when independently adjusting the value of $\theta$ for each set.

## Multiview Symbolic Regression (MvSR)

In this paper, we propose Multiview Symbolic Regression (MvSR), a different formulation for symbolic regression to search for parametric functions capable of describing different sources of data (i.e., views) with interpretability in mind.

## Multiview Symbolic Regression (MvSR)

The desiderata of this formulation are:

- allow multiple data as input
- independent parameters optimization for each dataset
- choice of aggregation function for the losses
- finer control of the maximum number of free parameters
- ability to reuse parameters
- penalization for a large number of parameters

## Multiple data in - Model out

Allowing multiple data describing different views require some adaptations for traditional SR algorithms:

- When fitting a model, each dataset must be fitted independently as they may have been generated by variations of the studied process
- As such, though they share the same functional form, the parameters might differ
- The parameters will be fitted independently for each dataset
- The fitness of the individual must be an aggregated score of the accuracy of these multiple datasets

## Aggregation score

The aggregation function can e:

- **best:** returns the accuracy of the best fitted model; it will favor the search of at least one good fit.
- **worst:** returns the accuracy of the worst fitted model; it will ensure a minimal accuracy.
- **average:** returns the average accuracy.
- **harmonic mean:** returns an average of the accuracy weighted on the worst fit.

In this work we will use the **worst** agregation function.

## Minimal parameters

A finer control on the number of parameters allow to guide the search towards an interpretable model, where each parameter have a meaning:

- Ideally, the parametric function will have the right amount of parameters to be accuretaly fit each dataset but not more than necessary.
- We do not want models that is too flexible neither too rigid.

Penalizing the number of parameters will help to find the best balance; stipulating the right amount (with prior knowledge) will give even better control.

## Implementation

# Experiments

## Artificial data

## Hyperparams

## Results

## Real-world data 

## Beer's law 

$$log( 1/(A + exp(-B x)) )$$

-log(A + exp(-Bx))
B controls the linear part 
A controls the saturation point 
A = e^{peak} - e^{-B px}

-log( e^{py} - e^{-B px}  + e^{-Bx} )

## Distribution of returns 

$$A exp(B |x|^C)$$

## Supernovae

$$exp(-A t (B - exp(-C t)))$$

$$A / (B e ^{Ct} + e^{-Dt})$$

## Conclusions

## Ack

## Thank you
